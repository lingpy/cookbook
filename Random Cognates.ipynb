{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Cognates\n",
    "\n",
    "At times you may want to compare how well an algorithms performs against a completely random algorithm for cognate cluster annotation. Here's how you do it. We use the ```random_cognates``` function which assigns words to random cognate sets and check how well these random cognates correspond to our gold standard. We use the ```bcubes``` function which computes B-Cubed F-Scores for the purpose of evaluation to check the accuracy of our random cognate judgments. First, we import the relevant functions (we also import ```test_data``` to have access to LingPy's test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lingpy import *\n",
    "from lingpy.tests.util import test_data\n",
    "from lingpy.evaluate.acd import random_cognates, bcubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test on Kessler's (2001) dataset, which has a lot of unrelated languages and therefore large amounts of unrelated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1:\t0.38\t0.91\t0.53\n",
      " 2:\t0.37\t0.92\t0.53\n",
      " 3:\t0.37\t0.91\t0.53\n",
      " 4:\t0.36\t0.93\t0.52\n",
      " 5:\t0.39\t0.91\t0.54\n",
      " 6:\t0.38\t0.91\t0.53\n",
      " 7:\t0.38\t0.91\t0.53\n",
      " 8:\t0.38\t0.91\t0.53\n",
      " 9:\t0.37\t0.91\t0.53\n",
      "10:\t0.37\t0.91\t0.53\n"
     ]
    }
   ],
   "source": [
    "wl = Wordlist(test_data(\"KSL.qlc\"))\n",
    "for i in range(10):\n",
    "    random_cognates(wl, ref='T_'+str(i))\n",
    "    p, r, f = bcubes(wl, 'cogid', 'T_'+str(i))\n",
    "    print('{0:2}:\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}'.format(i+1, p, r, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat this analysis but this time using a data set with more cognates, namely our Chinese test set (```phybo.qlc```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1:\t0.36\t0.27\t0.31\n",
      " 2:\t0.44\t0.26\t0.33\n",
      " 3:\t0.37\t0.26\t0.31\n",
      " 4:\t0.42\t0.25\t0.31\n",
      " 5:\t0.40\t0.25\t0.31\n",
      " 6:\t0.40\t0.23\t0.30\n",
      " 7:\t0.39\t0.27\t0.32\n",
      " 8:\t0.38\t0.29\t0.33\n",
      " 9:\t0.42\t0.26\t0.32\n",
      "10:\t0.40\t0.25\t0.31\n"
     ]
    }
   ],
   "source": [
    "wl = Wordlist(test_data(\"phybo.qlc\"))\n",
    "for i in range(10):\n",
    "    random_cognates(wl, ref='T_'+str(i))\n",
    "    p, r, f = bcubes(wl, 'cogid', 'T_'+str(i))\n",
    "    print('{0:2}:\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}'.format(i+1, p, r, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see, and what is interesting in this context is that we achieve rather high scores on the Kessler dataset, while our scores on the other dataset are rather low. This is surely related to the number of concepts in the data as well as the number of languages, but also the overall \"cognate density\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
