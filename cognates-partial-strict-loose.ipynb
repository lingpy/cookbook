{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Cognate Sets: Partial, Strict, and Loose Cognates in LingPy\n",
    "\n",
    "\n",
    "Handling partial cognates in LingPy can be done in a rather straightforward way, using the `Partial`-class of the `compare` package. If one wants to use this data in \"classical\" analyses, partial cognates need to be converted to \"normal\" cognates. The `Partial` class offers also solutions for this conversion. In the following, we will learn how to load a file containing partial cognates in LingPy, converting the data to two different formats of normal cognates derived from partial cognates, and saving the data as a nexus file in multi-state format apt for the usage with Paup.\n",
    "\n",
    "Let's start by loading a file that contains cognate sets and exporting it to binary format.\n",
    "Our file of choice is a dataset used in the study of [Hamed and Wang (2006)](http://bibliography.lingpy.org?key=Hamed2006). The second author of the paper was so friendly to provide us with the data, which we converted to LingPy format so that it can be easily manipulated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers.util import data_path # path to our cookbook data\n",
    "from lingpy import *\n",
    "wl = Wordlist(data_path('Wang2006.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the file, let's look at its content, by querying the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wangid, partial, doculect, concept, ipa\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(sorted(wl.header, key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column we are interested in here is the column \"partial\", since it contains the partial cognate information in this dataset (most cognates sets are only partially cognate in Chinese dialects). The cognates are given as Chinese characters, as it is traditionally done in Chinese linguistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chengdu 手\n",
      "Fuzhou 手\n",
      "Guangzhou 手\n",
      "Lianchang 手骨\n"
     ]
    }
   ],
   "source": [
    "for k in wl.get_list(concept='hand', flat=True)[3:7]:\n",
    "    print(wl[k, 'doculect'], wl[k, 'partial'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a small part of all the words for \"hand\", but it shows that Lianchang has two characters for \"hand\", indicating a two-syllable word, while the others have one and the same character. In terms of partial cognates, we would note this as:\n",
    "\n",
    "Doculect | Partial Cognate Set\n",
    "--- | ---\n",
    "Chengdu | 1\n",
    "Fuzhou | 1\n",
    "Guangzhou | 1\n",
    "Lianchang | 1 2\n",
    "\n",
    "In order to convert the data in this form, we re-number all Chinese characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble characters for chinese data\n",
    "nums = {}\n",
    "idx = 1\n",
    "for k in wl:\n",
    "    for char in wl[k, 'partial']:\n",
    "        if char in nums:\n",
    "            pass\n",
    "        else:\n",
    "            nums[char] = str(idx)\n",
    "            idx += 1\n",
    "wl.add_entries('partial_ids', 'partial', lambda x: [nums[y] for y in\n",
    "    x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need another hack, as we want to convert the partial cognates to full cognates, using two different methods. `Partial` expects a column \"segments\" as input. So we create it, using the `add_entries` function. The content of this column is of no interest for us, as we don't want to compare strings. We only want to deal with the partial cognate sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wl.add_entries('segments', 'ipa', lambda x: 't t t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data into partial, and compute full cognate sets of the partial ones. Here, `Partial` offers two versions:\n",
    "\n",
    "1 strict cognates (only words identical in *all* aspects will be judged to be cognate)\n",
    "2 loose cognates (all words that form a connected component in a network of shared cognate morphemes are judged to be cognate)\n",
    "\n",
    "The difference is easily illustrate:\n",
    "\n",
    "Language | Partal Cognate Sets | Strict Cognate Sets | Loose Cognate Sets \n",
    "--- | --- | --- | ---\n",
    "Lang1 | 1 2 | 1 | 1\n",
    "Lang2 | 1 3 | 2 | 1 \n",
    "Lang3 | 3 4 | 3 | 1 \n",
    "Lang5 | 2 4 | 4 | 1\n",
    "\n",
    "While in the strict cognate sets, all words are NOT cognate, they are cognate in all loose cognate sets. Why so? Because if we connect all words which each other which share at least one cognate set in common, we will have one line of connected words! Even if Lang2 and Lang4 do not share any morpheme with each other, they will be loosely cognate, as the words can be linked to words which themselves can be linked to the other words.\n",
    "\n",
    "In the `Partial` class, we can easily create these data, using the `Partial.add_cognate_ids`-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lingpy.compare.partial import Partial\n",
    "part = Partial(wl, segments='segments')\n",
    "part.add_cognate_ids('partial_ids', 'strictid', idtype='strict')\n",
    "part.add_cognate_ids('partial_ids', 'looseid', idtype='loose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data to file is now straightforward, as we only need to use the `output` function. Here, we specify \"multistate.nex\" as format, in order to output the data in Paup format for multistates. We set missing characters to \"?\", and export the data for two reference points: the loose and the strict encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export multistate format\n",
    "part.output('tsv', filename='Wang2004', ignore='all', prettify=False)\n",
    "part.output('multistate.nex', filename='Wang2004-strict', ref='strictid', missing='?')\n",
    "part.output('multistate.nex', filename='Wang2004-loose', ref='looseid', missing=\"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how the file for loose encoding looks in the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NEXUS\r\n",
      "\r\n",
      "BEGIN DATA;\r\n",
      "DIMENSIONS ntax=23 NCHAR=200;\r\n",
      "FORMAT RESPECTCASE DATATYPE=STANDARD symbols=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOP0123456789\" GAP=? MISSING=? interleave=yes;\r\n",
      "OPTIONS MSTAXA = POLYMORPH;\r\n",
      "\r\n",
      "MATRIX\r\n",
      "\r\n",
      "Anyi       (ef)caaa(cf)aaaaabcabaa(ce)aaaa(bd)aba(bce)aaaaab(ab)aaaabba(ae)aa(bc)aaaaaaaaaaaabaaaalaaaaaaaeaaaadacaaaadabacaaaaaaaaaba(ab)aaaaa(ab)aabaaabadaaaakceaaaaaaaabaabjaaaaabaaaaacaaabaaca(mn)aaaaaeaaaaabaaabaasbbaaaaabaaaaaaaaaaaaaaaaaa\r\n",
      "Beijing    i(ab)baacaaaaaacababc(ac)aaabababaaaaaea(be)aaabbaeaa(ce)aaaaaaaa(ab)aaabacaaa(ad)aaaaaa(cf)aaabdadaaaa(afg)aba(dij)aaaaaaaadbaaa(ad)aaaaaa(ac)aaabadaa(ac)aa(ch)baaaaaaaa(ab)aacaa(abcd)abaaaaaaabbaacaa(ac)bb(cd)aaaaabaaaabaaa(bf)aatcbaaaaabaaaaaaaabaaaaaaaa(ae)\r\n",
      "Changsha   fbbaacaaaaaa(bc)abaa(ac)aaaa(bc)aba(ab)aaaeabaaaaabba(ae)aacaaaaaaaaaaaabaaaabaaaaaaacaaaadadaaeaaabadaaaaaaaaabaaaaaaaaaaaaaabadaaaaa(ac)(ab)aaaaaaaa(bdl)aaaaaaabaaaaaaa(bc)baa(ab)aa(ac)bb(ac)aaaaf(ab)aaaabaaabaa(AB)cbaaa(ab)abaaaaa(ae)aabaaaaaaaaa\r\n",
      "Chengdu    eabaacaaaaaababaacaaaabababbaaaaeakaaabbaeaacaaaaaaaaaaaabacaaaaaaaaaacaaaadadaadaaabadaaaaaaaaebaaaaaaaaaaaaaabadaaaagcfaaaaaaaa(bd)aacaaaabaaaaaaabbaabaacbfcaaaacbaaaabaaabaan(ac)baaaaabaaaaaaaabaaaaaaaaa\r\n",
      "Fuzhou     eeabb(ab)aaaaaa(ac)a(ab)aa(ac)aaba(ac)a(cd)a(fg)aa(ab)gcd(ac)(bf)aaaacadaaaaaaaaaaaaaadaaaa(ab)gaaaaaaabaaaa(de)b(ef)aaaa(ad)(ab)ba(def)ba(ab)aabaacbaaa(ac)caaada(ab)aaabaaa(ab)bbfd(de)aaaaaa(ae)a(fg)aaaaa(ak)adaaaaaaa(ce)caabac(ah)bgaaaaafaaaaa(bf)aaabcai(bc)baaaa(ad)aaaaca(ab)aeaaaaaaaaac\r\n",
      "Guangzhou  ac?aa(bc)aaaaaab(ab)bad(ab)aaaa(ab)(ab)aacaaa(ad)aaa(abc)aaaaaa(ab)aa(acf)aaaaaaaaaaaabaaaad(ab)aaaaaaaaaaaa(ad)(abc)aafa(ad)a(ab)a(ab)aaaaaaa(ab)aa(ab)aa(ab)aaaa(ab)aaaaaba(ef)aaaaa(cmn)eaaa(ae)(ab)a(ac)a(abc)aa(ab)(ab)aia(ab)(ab)aaaaaacbaaba(ab)(gh)abaaaaafaaaaabaaa(ab)aa(abc)(ae)aaaaaaaaaaaafaaaaaa(ab)?aaaa\r\n",
      "Lianchang  (ef)gbaaca?a(ab)aaaa(ab)aadaaaabacchaaaaacaiaaaacaaaabaaaaaaaaaaaababaa(fh)aaabaaaaaaaadcgaciadabd(de)aaaaaaaaecaaaaaacadabaaaba(bh)aaaacadaaa?aaaa(cf)aabfalaaaaaaaaaccaabadcdiaaaaaaaaaaehaaadaakbbaacaeaaaaaaaaaaaaaa?aaaa\r\n",
      "Meixian    c(cd)?aa(ch)a?aaa(ab)aa(ab)aa(ab)aaaaba(ac)(bc)(ce)aaaaacb(ad)aaaacaaaa(acg)aaaaaaaaaaa(ac)babaafaaabaaaaaaaacadabhada(bc)c(ad)aaaaaaaabaaaaaaacacabaaabaeaaaa(cd)(ab)da(ab)aaaadaeaa(ab)(cd)aaabbaaaaaaccaabachceaaaaafaaaabdaba(bc)aaf(ac)baa(ab)acaaaaaaaaaaaaaaaaaaa\r\n",
      "Nanchang   d(bc)?aaca?aaaababaacaaaababc(ab)aaaaaba(be)aaabbaaaacaaaaaaaaaaaaba(ac)aa(ab)aaaaaaaaaaaadadaaaa(ad)abadaaaaaaaaabaaaaaaaaaabaaabadaaaa(ae)c(bde)aaaaaaaa(abd)aabeaabaaaaaaaa(bc)aaabaa(aj)cf(ac)aaaacaaaaceaaabaa(gh)(ad)baaaaabaaaaaaaa(ab)aa(ab)aaaaaa\r\n",
      "Ningbo     (eg)daaacaaaaaababaacaaaababaiaaahaeabaaabbaeaacabaaaaaaaaaabaaaaiaaaaaaadaaaafahaadadabccaaaaaaaafbaaaaaaaaaabaaabagaaaahcbaaaaaaaadaacgaaaeaaaaaaabaaabaaabebabaaabaaaficaaeaalcbaaa(ab)abaabaacaabaaaaaaaaa\r\n",
      "Ningxia    efaaaca?aaaababaacaaaaaababbaaaaea(gh)aabbbaeaacaaaaaaaacaaabacaaaaaaaaaacaaaadadaadaaabadacaaaaaadbaaaaaaaaaaaaaabadaaaagcbaaaaaaaaaaacaaaabaaaaaaabbaabaaabhcabaacaaaa(ad)(bg)aaabaajabaaaaabaaaaaaaabaaaaaaaaa\r\n",
      "Shanghai   (eh)(bjk)?aacaaacaababaacaaaababaiaaacabadaaabbaeaabaaaaaaaaaaaabaaaae(ac)aaaaaabaaaahadaac?eabcgaaaaaaaaabaaaaaaaaaabaaabagaaaabcbaaaaaaaaaaaabaaabaaaaaaabbaabaaabebabaaabaaaikaaabaapabaaa(ab)abba(ac)aacaaaaaaaaaaad\r\n",
      "Shanghai_B (eh)lbaacaaacaababaacaaaababaiaaacabadaaabbaeaacaaaaaaaaaaaabaaaae(ac)aaaaaabaaaahadaacaeabcgaaaaaaaaabaaaaaabaaabaaabagaaaabcbaaacaaaaaaaaiaaabaaaaaaabbaabaaabebabaaabaaailaaabaaqabaaa(ab)abba(ac)aacaaaaaaaaaaad\r\n",
      "Shuangfeng f(bc)baacaaaaaa(bc)abaa(ag)aaaa(bc)a(be)a(ab)aaafa(bh)(ab)aaaabbahaacaaaaaaaaaaa(ab)baaaacaaaaaaacaaaadaoaaaaa(ad)dadaaaaaaaaabaaaaaaaaaabaaabadaaaaga(cd)aaaaaaac(bd)aa(ab)oa(ah)ahaaaaaaacaaa(ab)aa(ac)fbaaaaaj(ab)aaaabaaabca(CD)dbaaa(ab)aaaaaaaaaa(ab)aaaaaaaaa\r\n",
      "Suzhou     bdaaa(cg)aaaaaababaacaaaababbdaaacaba(bd)aaabbacaacaaaaaaabaaaabaaaaeaaaaaaagaaaabadaaga(ab)(ab)bacaaaaaaacabaaaa(ab)aaaaabaaabagaaaab(ac)baaaaaaaadaa(ac)aa(aj)acaaaaaaabbaabaa(ai)bdbabaa(ck)bbaaacbaabaa(de)bbaaa(ab)a(bc)baa(ab)aaa(ad)aaaaaaaaab\r\n",
      "Taibei     e(gh)ba?caaaab?aaaaceaaaabacc(fl)(ac)a?bafclcaaacaeaaaaaaaaabaaaaaaaaabnaaabaaabaaaaibmaabacabbebaaaabaa(ch)baaaccaaadabaaabacabaan(kl)daaaaaabafaaa(al)aaacaaaaaaaccaabac(ef)haaaaaahaaaa?bdaabbawbbaahbaaaad?cbacacaadaaaac\r\n",
      "Taiyuan    eabdacaaaaaababaacaaaabababaaaaaeabaaabbaaaacaaaaaaaaaaaabacaaaaaaaaaac(ab)aa(ab)da(dn)aadaaabada(ab)aaaaaa(de)baaaaaaaaaaaaaabadaa(ac)agcbaaaaaaaa(ad)aac(an)a(ag)abaaaaaaabbaabaa(ac)bbcaaaacbaaaabaaabaa(xyz)cbaaa(ab)abaaaaaaaabaaaaaaaaa\r\n",
      "Wenzhou    jmb(ac)acaaaaaa(abc)abaaca(ab)aaba(be)a(af)aabaa(bg)a(bno)aaabcagaa(ac)aaaaaaa(ac)aaa(ae)baaaamaaaaaaaaaaaada(kl)aaca(abd)aba(kl)aaaaaaaa(cg)(bd)aaaaaaaaaabaaabadaaa(ab)(lm)(dij)(bi)aaa(ad)(ac)aaa(ak)aaakaaabaaaaaaad(ad)aabaad(bfg)eaabaa(fg)(ab)aaaabaaa(be)aa(uv)(bc)baa(ag)aa(ab)(ac)aa(ac)bdaaaaaaaaaaaa\r\n",
      "Wuhan      e(ab)baacaaaaaa(abc)abab(acg)aaaababa(ab)aaa(ad)(ab)(eh)a(bj)aaabbaeaacaaaaaaaaaaaabaaaa(ab)(ae)aaaaaacaaa(ab)dadaaaaaabadaaaa(ab)aaaebaaaaaaaaaaaaaabadaaaaa(acm)baaaaaaa(ab)(bdhi)aacma(aef)abaaaaaaabbaabaa(ac)b(bc)caaaa(ci)(ab)aaaabaa(ab)baapcbaaaa(ab)baaaaaaaabaaaaaaaaa\r\n",
      "Xiamen     eh(ab)aaeaaaabaaaaaa(ef)(ab)aaa(bd)aca(bck)aa(ad)ba(df)c(dmn)ba(ac)acaeaa(ad)aaaaaabaaaa(ad)aa(ad)abkaaabaaabaaaadbja(ab)(ab)a(ac)abc(dh)(ab)aaaabaacbaaaccaaadabaaaba(abc)aaa(ab)f(acg)(bh)aaaaaaaa(af)aaahaa(ab)(fg)aaaaaaaccbabacb(be)baaaaabaaaaa(abm)aaabfar(bc)baa(aef)aaaaaddaba(ab)aaaa(ac)aaaac\r\n",
      "Yingshan   fb?aacaaaaaabababaaaaabaeabbaaiaea(adj)aaabbaeaacaaaaaaaaaaaabaaaabaa(ab)aaaacaaaadadaaaaaabadaaaaaaaaebaaaaaaaaaaaaaaaadaaaaa(ae)(be)aaaaaaaa(bdhi)aacaaaaaaaaaaaabbaacaacbjcaaaabaabaabaaabdamcbaaaaabaaaaaaaabaaaa?aaaa\r\n",
      "Yuci       d(ab)baacaaaaaababaacaaaabababaaeaaeabaaabbaaaacaaaaaaaaaaaabacaaaaaaaaaacaaa(ab)da(dn)aadaa(ac)badaa(ac)aaaaa(de)baaaaaaaaaaaaaabadaa(ac)agcbaaaaaaaabaac(am)aaabaaaaaaabbaabaa(ac)bbcaaaacbaaaabaaabaa(xyz)cbaaababaaaaaaaabaaaaaaaaa\r\n",
      "Zhanping   e(hi)baadaaaaaaaaaaaeaaca(bd)accj(ac)acba(cdf)c(bl)(ab)a(ac)acafaaaaaaaaabaaaaaaaaa(ab)(fj)aaabaaabaaaagbia(ab)aa(ac)abadbaaaacaacbaaaccaaadabaaaba(ab)aaab(ij)(afg)(bdg)aaa(ab)aaaajaaahaaacaaaaaaa(ac)cbabac(kl)b(kl)aaaaa(bd)aaaa(gh)jaaabeaobbaad(ab)aaaaadabaeabaacaaaac\r\n",
      "\r\n",
      "\r\n",
      "END;\r\n"
     ]
    }
   ],
   "source": [
    "cat Wang2004-loose.multistate.nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
